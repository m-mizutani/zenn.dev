---
title: "実運用への統合と今後の展望"
---

本章では、これまで構築してきたセキュリティ分析LLMエージェントを実際の業務にどのように統合するか、そして今後の技術展望について解説します。

# Warren システムの全体像

本書では、これまでセキュリティ分析LLMエージェントを開発のしやすさの観点から、CLI上で動作するように実装してきました。しかし実際のセキュリティ分析業務においては、CLIでは不便なことが多く、あまり実用的ではありません。そこで、これまで解説してきたLLMエージェントに関する実装の知識をベースに、実際にどのようなシステムを構築すると業務に活かせるかを解説します。

本章で紹介するwarrenは、LLMエージェントを組み込んだセキュリティアラートの管理および分析のオンラインシステムです。

https://github.com/secmon-lab/warren

## アラート管理とアラート分析システムの統合

まず、この2つを統合することに意味はあるのかについて整理します。アラート分析とは、これまでの章で解説してきたように、アラートに関連する情報を各所から集めて必要に応じて深掘りし、最終的に集めた情報をもとにアラートによる影響を判断することです。一方、アラート管理とは、アラートとして発報されたものの対応状況を記録管理するものです。具体的には、ステータス（未対応、対応中、対応完了）、結論（誤検知、検知は正常だが影響なし、実際に影響が見られた）、エスカレーションの有無（インシデントレスポンスとして別システムで対応されたかなど）といった情報を管理します。なお、ここでは「アラート管理」を影響のあるインシデントかどうかの判断までとします。インシデント対応まで含めたアラート管理システムもありますが、インシデント管理システムは別立てしている場合も多いためです。

従来、これら2つの機能はそれぞれ別々で構築運用されていました。アラート管理はチケットシステムやSIEM上のアラート情報などで管理され、分析はSOAR（Security Orchestration Automation and Response）でのワークフローやSIEM（Security Information and Event Manager）上での検索などで実現されていました。従来の業務フローを考えると、それでも機能していました。分析はSOARで一部自動化されるものの、ほぼ必ず人間の手が介入するため、無理に統合する必要はなかったのです。人間が対応する部分は直接的にアラートと紐づけて記録されるものではありませんし、記録したところであまり活用の道筋もありませんでした。初心者が熟練者の作業記録を見て学ぶといったケースはありえますが、実地でそうした活用をするのは稀と考えられます。

しかしLLMエージェントを利用すると、状況が大きく変わってきます。まず、分析の過程が容易に記録でき、その記録を記憶システムなどで利活用できるようになります。アラート（あるいはアラートを管理するチケット）と密結合していることで、プロンプトエンジニアリングによる情報の注入が容易になります。さらにFunction Callingを使えば、アラートそのものへの操作として、アノテーションなどもエージェントにやらせることができます。対応する対象と対応状況の記録を密結合させることで、アラート発出後の対応の見通しもよくなります。

こうした観点から、AIエージェント活用の側面では管理および分析を統合する価値が高いといえます。なお、インシデント対応についても同じような価値を発揮できる可能性がありますが、筆者はそのようなインシデントに相まみえる機会が今のところ少ないため、ここでの言及は避けます。

## アラート管理・分析システムの要件

アラート管理・分析システムに求められる要件について簡単にまとめます。

### アラートの受信

アラート管理・分析システムは、自身でアラートを発見する機能は持ちません。そのため、外部のセキュリティ監視・防御システムや、SaaS（例えばGoogle Workspace）のセキュリティアラートを受け取る必要があります。受け取る方法は様々ですが、Webhook APIやSQS、Pub/Subなどのリクエストを受け取れるようにしておくと柔軟に対応できます。APIでpullする必要があるシステムについても、スクリプトなどで取得して流し込めば対応可能です。アラートを受信した際には、変換（ingest）、情報付与（enrich）、不要なアラートの棄却（triage）といった処理をワークフローとして自動実行できるようにします。

### アラートの対応・分析

対応・分析は、なるべく使い慣れたツールで行いたいという要件があります。独自UIでもよいのですが、やはり使い慣れているものがやりやすいです。通知を受けたあとにいちいち別のシステムに遷移するのも面倒です。

一方で、分析の過程や結果といった記録自体は、後から参照したり記憶システムで活用したりするために、システム内にちゃんと閉じ込めておきたいという点も重要になります。この「使い慣れたツールで作業できる」と「記憶を適切に管理する」という2つの要件を両立させる必要があります。

また、関係者とコミュニケーションが取りやすい仕組みが望ましいです。アラート対応の業務では、体感で1/3程度が「人に聞く」という作業になります。例えば「不審と思われるリソースが作成された」というアラートが上がったとき、関係者を探し出してそれが意図的だったか、意図的だとしたらどういう目的だったかを確認する必要があります。独自UIだと、そこに関係者を誘導しないといけません。関係者は当然ながらセキュリティに関係しない人を含むというか、むしろ99%がそちらです。そうするとその人達向けにもアカウントを用意したりといったことが発生して手間がかかります。物によってはライセンス数の問題もあります。さらに単純にコミュニケーションが途切れると面倒です。例えばSlack上で話していたことをもう一度転記したりするのは非効率的です。そのため、シームレスにコミュニケーションをとれる仕組みが望ましいといえます。

### アラートの管理

アラートがどういう状況かをちゃんと把握したいという要件があります。アラートそのものの状況（未対応、対応中、対応完了）や影響度の判断、誰が担当しているのか、対応でどのような過程を辿ったのかといった情報を記録すべきです。

ここで重要になるのが、似たようなアラートの処理です。Embeddingの章でも触れましたが、似たようなアラートが大量に出たときに、それを個別に対応しないといけないというのは非効率的です。こういったものを一括で処理できるようにしたいという要件があります。

# UI統合の実装

Warrenでは、これまでに解説してきた要件を踏まえた実装を行っています。

## アラート受信

![](https://storage.googleapis.com/zenn-user-upload/bfd53171cff8-20251221.png)
_受信したアラートについてSlackへ通知が送信される_

warrenでは、一般的なWebhookやPub/Sub、SNSといったAPIに対応しています。ワークフローについては第13章と第14章で解説したものとほぼ同様なので、ここでは省略します。

事前に定義したenrichおよびtriageのポリシーに基づいて、通知を抑制したり、そもそもアラートとして取り扱わない（無視）するといったことも可能です。例えばセキュリティ監視のアラートについては無視するのが怖いため、基本的には全て受け入れるようにします。一方でセキュリティ関連のニュース記事をアラートと見立てて処理することも可能です。RSSフィードを受信したらAPIへPostするスクリプトを別途用意し、プロンプトで自組織の状況、使っている技術スタックやツールなどの情報を与えておけば、全く関係ない記事は無視させるといったことができます。

セキュリティ監視のアラートについては、事前に調査するエージェントを実行しておくこともできます。ただしアラートが頻発したときに、外部APIをたたくレートリミットにヒットしないかだけ注意が必要です。

## アラート分析

![](https://storage.googleapis.com/zenn-user-upload/e8a73dcfbf47-20251221.png)
_Slackのスレッド内でエージェントと会話形式で指示が可能_

![](https://storage.googleapis.com/zenn-user-upload/8441b7562bb4-20251221.png)
_質問されたことに対して結論が得られたら報告してくれる_

分析については、まさにこれまで実装してきたLLMエージェントと同等の機能を提供しています。ボットをあらかじめ用意しておき、それに対してメンションすると必要な情報をかき集めてくれます。設定したツールに応じて計画を立てて実行してくれる（Plan&Execute）ため、図の例では脅威情報を集めているだけですが、ログ検索の実行もしてくれます（BigQueryツールとサブエージェント実装）。

エージェントの結論自体をそのまま採用する必要はありませんが、一般知識も交えた回答をしてくれます。より精度の高い回答をさせたい場合は、組織の状況をシステムプロンプトに組み込んでおくとよいでしょう（プロンプトエンジニアリング）。

## アラート管理

![](https://storage.googleapis.com/zenn-user-upload/5696d8e6495a-20251221.png)
_Webインターフェイスにおけるダッシュボード_

アラートの管理という側面ではWeb UIを活用したほうがよいでしょう。Slackはフロー的に情報を扱うのには適していますが、ストック的に扱うのは難しいためです。大量のアラートを処理したり、残アラートを確認したり、対応の記録を見たりするといった作業は、専用UIの方が自由度が高くなります。

従来であれば、ユーザインタフェースをSlackとWeb両方に持つというのはメンテコストが高くてアンチパターンでした。しかし生成AIを活用したコーディング支援により、UI実装の開発速度が大幅に向上し、現実的な工数で両方を維持することができるようになりました。インタラクティブなやり取りや、他の組織内メンバーとのやりとりなどはSlackに圧倒的な利がありますが、その他の操作はWeb UIを活用するのがよいでしょう。特殊な操作をするインターフェイスも、Web UIの自由度の高さに利点があります。

![](https://storage.googleapis.com/zenn-user-upload/8d2427a643d2-20251221.png)
_例としてアラートを事前に類似度でクラスタリングして、まとめて起票するといったインターフェイスも用意できる_

Warrenはアラートを「チケット」という単位で管理しています。チケットはあくまで対応の単位であり、1つ以上のアラートを紐づけることができます。同じ事象を指していると見られるアラートをまとめることで、効率的に対応を進めることができるわけです。個別のアラートを一つずつチケットに紐づけていく"Bind"という機能も用意していますが、似たようなアラートが大量に発生した場合は、一つずつ対応するのは非効率的です。

そこで、Embeddingを利用した類似度検索およびフィルタによって、類似アラートを一括で処理できる機能も実装しています。これにより、例えば同じ脆弱性に起因する複数のアラートや、同じ攻撃元からの一連のアクセスといったものを、まとめて一つのチケットとして対応することができます。

![](https://storage.googleapis.com/zenn-user-upload/6025c4cebc92-20251221.png)
_類似アラートの一括処理画面_

## Warrenの実運用に関する所感

warrenは実際に筆者の業務内でも利用しており、プロトタイプも含めた運用期間は約1年ほどとなりました[^1year]。その実運用での効果や課題について紹介します。

[^1year]: プロトタイプの実装が2024年6月までで、実際に実装をして動かし始めたのが2024年7月からです。当初はまだ実用的なLLMエージェントの構築手法が確立されておらず、セキュリティ分析における生成AI活用の模索をしていた期間も含まれています。

### 分析業務の省力化

筆者のようにある程度セキュリティ分析ができるメンバーであれば、分析業務の大幅な省力化になります。脅威情報を調べるといった作業も簡単ではありますが、一定の手間がかかります。特に効果が大きいのがログ検索です。

筆者の業務環境ではBigQueryに全てのログが入っていますが、スキーマが大きすぎて人間には覚えられません（テーブル数は数十、各テーブルのカラム数は数百から数千）。そのためこれまでは、よく使うSQL文をrunbook（手順書）のような形であらかじめ用意し、人間がアラートに応じてパラメータや条件をちまちま編集して使っていました。これがLLMエージェントを導入することで、BigQueryのスキーマ情報とrunbook、分析目的をあたえるだけで、LLMが適切なSQLを自動生成して実行してくれるようになりました。作業が大幅に楽になっただけでなく、分析に際して「重い腰を上げる」といった心理的障壁が激減したのも大きな効果です。正直、一度このLLMエージェントでの分析に慣れてしまうと、人手だけでやる気にはなれません。

### 非専門メンバーの分析業務サポート

セキュリティ分析が専門ではないメンバーも、一定のサポートはしつつも分析業務ができるようになってきました。最終的な判断について助言したりといったことはありますが、あやしいものや判断に悩むものをエスカレーションしてもらうことでうまく機能しています。特にSlackやGitHubから社内活動の情報をFunction Callingによって拾ってきて、それが正規の動作かどうかを確認することもできるようになっており、かなり助けになっています。

# 深刻度判定の自動化に向けて

本書を通して実装してきたLLMエージェントは、あくまで分析、あるいは分析の補助をするものとして役割を期待してきました。これは、LLMエージェントには深刻度の判断が難しく、最終的な判断は人間がやること（human-in-the-loop）というスタンスをとってきた結果です。しかし本当にそれで満足でしょうか？ 昨今のLLMの発展を鑑みるに、もっと期待してもいいのではないでしょうか。

本セクションでは、今後の構想として深刻度判定の自動化について説明します。これは筆者がこれから取り組もうとしている構想であり、本書で実装したLLMエージェントをさらに高度化するとしたらどうするか、という内容になります。

## 本当にやってほしいこと

セキュリティ監視業務というなかで本当にLLMエージェントにやってほしいことの一つは、深刻度の判定をやりきることです。ここでいう **深刻度（severity）** とは、実際に組織にとって被害がでる確度の高さ（影響度）、およびどのくらい急いで対応する必要があるか（緊急度）を統合したものと定義します。

これができるようになると初期トリアージを自動化できるようになります。本当に対応が必要なアラートだけに人間が介入すればよくなるため、ある程度の防御ができている環境であればアラートの9割近くは影響のないものとなり、実際に影響がある（侵害が発生している、あるいは直近で発生する可能性が高い）ものだけに人間の対応を限定できます。言い換えれば、これはオンコールの一次請けができるようになるということです。これによって人間がオンコールで24時間365日張り付く必要がなくなります。中小規模の組織（例：従業員500人程度まで）では24時間365日体制を作るのは極めて困難であり、この機能が実現できると大きな助けになります。

なお、インシデントレスポンスや問題の修正もやってほしいところですが、これはさらに難しく、またドメインも異なり筆者も詳しいとは言い切れないため今回は割愛します。

## なぜ深刻度判定が難しいのか

もちろん現状でもLLMに「このアラートの深刻度はどの程度か？」と尋ねれば回答してくれます。しかしやったことがある人ならわかると思いますが、全く期待した答えにはなりません。これは組織やシステムの状況にかかわらず、一般的な回答になってしまっているためです。例えるなら[CVSS](https://www.first.org/cvss/)のようなものです。CVSSはソフトウェア脆弱性のリスクを定量化してくれますが一般化された内容であり、組織固有の文脈を反映していません。CVSSスコア8の脆弱性よりもスコア5の方が組織によっては深刻ということも当然ありえます。LLMもこれと同様に、組織内の文脈を無視して「一般的な」影響の有無を判断してしまいます。

他方、LLMのモデル自体の性能はどんどん上がっており、論理的な回答を導くというプロセスだけで考えれば、すでに十分な推論力を持っていると考えられます。例えばSWE-benchなどのソフトウェアエンジニアリングタスクのベンチマークでは、最新モデルが大幅な性能向上を示しています[^swebench]。では何が足りないのかというと、ここからは仮説になりますが、ここまでもずっと言及してきた通り **単純にコンテキストが足りない** と考えられます。分析に伴ってアラートそのものだけでなく様々なコンテキストを与える必要があります。これを適切に与えられるようになったとき、深刻度判定の精度の向上が見込めるのではないかと予想されます。

[^swebench]: https://www.swebench.com/

## 足りてない情報は何か

では、適切な深刻度判定を行うためには具体的にどのような情報が必要なのでしょうか。自分でアラートを分析し深刻度を判断するとき、何を参考にしているかを思い返すとわかりやすいでしょう。LLMは情報を揃えればある程度妥当な判定をしてくれるようになってきました。つまり、自分が深刻度判断するときに使っている知識や集めている情報がそのまま必要になる、ということです。実際に整理してみると、必要な知識がとても広範にわたることがわかります。筆者の思いつく範囲で主要なカテゴリを整理すると以下のようになります。

### 組織のコンテキスト

まず、そもそもセキュリティ監視によって最終的に守るべき組織についての理解が必要です。

- **システムが扱うデータの機密性・重要度**: 個人情報、機密情報、公開情報などデータの性質によってリスクは大きく変わります。例えば公開情報しか扱わないシステムであれば情報漏洩のリスクは低くなります。またデータの機密性だけでなく、環境の性質も重要です。検証環境などで本番データが入っていない場合は、深刻度は比較的低めに見積もることができます。もちろん検証環境も攻略の足がかりになる可能性はあるので対応しなくて良いわけではありませんが、緊急度には影響します。逆に個人の医療情報を扱う本番システムであれば、漏洩時の影響は甚大です。
- **システムのビジネスインパクト**: システムが停止した場合のビジネスへの深刻度も重要な判断材料です。例えばECサイトであれば停止すると直接売上に影響します。社内の勤怠管理システムであれば外部への影響はありませんが業務は滞ります。これらによって緊急度が左右されます。
- **組織のリスク許容度**: 組織としてどの程度のリスクまで許容するのかという方針も重要です。扱っているサービスや業種によって法令・ガイドライン対応やレピュテーションリスクへの感度が変わります。これらによって同じアラートでも対応の優先度が変わってきます。

### 実装のコンテキスト

内外で利用している既成のシステムや、自社でプロダクトを提供している場合などはその実装の理解についても必要です。さらにそれを動かしているインフラや基盤についても、それらがどのような仕組みになっているか、現状どうなっているかによって影響は異なります。

**プロダクト・システムの実装**

検知されたアラートに関連する機能の実装詳細は重要な手がかりとなります。該当エンドポイントは何を処理しているのか、入力検証は実装されているか、使用しているライブラリやフレームワークのバージョンは何か、といった情報が必要になります。例えばSQLインジェクションの疑いがあるアラートでも、ORMを使っていてパラメータ化クエリが徹底されていれば影響は低くなります。一方で文字列連結でクエリを組み立てているような実装であれば、高リスクです。このように実装そのものを追跡できるような能力が必要です。

また細かい点でいうと、プロダクトの実装内容やシステムの認証設定も深刻度判定に影響します。不正ログインの試みを検知した場合でも、そのユーザやシステムにMFA（多要素認証）が設定されていれば影響はないと推定できます。ただし、これはどちらにしてもログを確認すべきではあります。逆にパスワードのみで認証していた場合、侵害を受けた可能性を判断する必要があります。

既知の脆弱性や技術的負債の有無も確認する必要があります。脆弱なライブラリのバージョンを使っていないか、過去のペネトレーションテストで指摘された未修正の問題はないか、といった情報です。これらがある場合、攻撃者が悪用できる既知の手法が存在する可能性が高くなります。

**インフラや基盤の設計や実装**

インフラや基盤の認可設定（権限設定）も確認が必要です。利用しているユーザ、サービスアカウントやロール、そしてその権限範囲などを把握する必要があります。強い権限を持つ主体が侵害された場合、影響は大きくなります。また重要なデータを扱う主体も同様です。逆に権限がちゃんと切られていてかつ重要なデータを扱っていなければ緊急度は低くなります。

インフラとしてのデータ配置や公開などの方針も重要です。インフラの設定としてデータ露出に関する方針がどうなっているのかを把握する必要があります。例えばオブジェクトストレージの公開範囲が任意のユーザになっていても、Webサイトの公開リソースであれば全く問題ありません。逆に意図せずそのような設定になっていて情報漏洩を起こしている可能性もあります。これは担当者に問い合わせるという方法もありますが、組織内になんらかのルールがあれば、それに則っているかどうかで影響を判定できます。

ネットワークセグメンテーションや境界防御の設定も見る必要があります。ネットワークが適切に分離しているか、疎通は必要最低限に設定されているか、といった情報です。これによって攻撃を受けたシステムから他のシステムへの横展開がどの程度可能かが変わります。例えば完全に隔離された環境であれば、そのシステムだけの問題で済む可能性が高くなります。一方でフラットなネットワーク構成であれば、一箇所の侵害が全体に波及するリスクがあります。

### 業務のコンテキスト

アラートに関連したユーザやシステムがどのような業務をしているかの理解も必要です。どのようなシステムと繋がって何をするためのシステムなのか、どのような業務をしている人でどのようなデータを扱う人なのか、といった情報を把握することで、適切な行動が推定され、アラートとして検知された内容が意図的なのかどうかの判断ができます。

当該システムに対する最近の変更履歴も重要な情報源です。直近のデプロイや設定変更はあったかを確認します。新しい機能をリリースした直後であれば、その機能に起因するアラートである可能性が高くなります。ただし設定変更によって意図せず脆弱な状態になっている可能性もあり、そこも含めて深刻度を判定する必要があります。変更履歴を把握していれば、少なくともアラートの原因を特定しやすくなります。

現在進行中のプロジェクトや業務イベントも考慮すべき情報です。新機能リリース直後ではないか、大規模キャンペーン実施中ではないか、といったタイミング情報です。これらのイベント時には通常と異なるトラフィックパターンが発生するため、このようなタイミング情報を加味することで、アラートの優先度を適切に判断できます。

### 脅威のコンテキスト

攻撃者の活動状況も判断材料になります。ドメインによっては同業他社への類似攻撃の発生状況が参考になります。例えば金融業界で特定のマルウェアキャンペーンが活発化しているという情報があれば、同様のアラートの優先度は上がります。

また最近活発な攻撃手法や領域に関する情報も、アラートの深刻度判定に影響します。脅威インテリジェンスフィードやセキュリティベンダのレポートから得られる情報を、組織の状況と照らし合わせることで、より精度の高い判定が可能になります。

# 今後の技術展望

ここまでで述べた通り、使うべき情報は多岐にわたり一筋縄ではいきません。これまで解説してきた通り、少なくとも現状ではLLMエージェントの適切な運用ではコンテキストウィンドウを適切に利用できるかが、結果を大きく左右します。これらのデータを無闇に全部渡せばいいというわけではないのが重要なポイントです。

この問題を解くのはとても難しいですが、いくつかのアプローチを組み合わせることで、この問題に対処できる可能性があります。以下では筆者が考えている解決策のアイディアをいくつか紹介します。

## 組織内情報の検索性向上

まず基本となるのは、組織に関連した情報をまとめ、エージェントが真の意味で検索可能な状態にすることです。ドキュメント、設計書、運用手順書、さらには事業関連の状況、セキュリティポリシー、組織図、業務分掌などの情報を検索可能な形で整備する必要があります。そもそもまずそれらの整備が必要であり、そのうえでシステムの機密性、ビジネスインパクト、リスク許容度なども含めて分かるように情報をまとめて検索可能にします。多くの組織では、こうした情報が散在していたり、属人化していたりするため、まずは情報の集約と構造化が第一歩になります。

ただし、おそらくただのRAGではうまくいきません。探すべき情報の範囲が横断的であり、エージェントが直接的に欲しい情報へたどり着くのは困難です。真の意味での「検索可能」は本当にエージェントがその情報にたどり着けてこそです。たどり着けないなら理論上は検索可能でも意味はありません。

そもそも何を探せるのか、ということからエージェントが知る必要があります。人間のアナリストであれば、経験から「こういう情報があるはず」という見当をつけて探索できますが、エージェントにはその経験がありません。これは「知らないものは探さない」問題と呼べるでしょう。

より効率的に知識・情報を検索するためには、より先進的なRAGのような仕組みが必要になります。例えば[GraphRAG](https://arxiv.org/abs/2408.08921?utm_source=chatgpt.com)のような技術が候補になります。GraphRAGは知識をグラフ構造（ノードとエッジ）で表現し、関連情報をノード間のパスを辿って芋づる式に検索する技術です。単純なベクトル検索では見つけにくい間接的な関連情報も取得できるようになります。ただしセキュリティ分析という文脈・ドメイン特有の問題もあると考えられ、実地でいろいろと試していくしかありません。

また、検索されたドキュメントやポリシーなどをそのままエージェントに渡すと、単にコンテキスト消費が多くなるだけになってしまいます。重要なのは検索から得られた情報を、うまく咀嚼して今の状況にあわせて解釈し、適切な形でメインエージェントへ返すことです。ここでもサブエージェントが活躍します。検索を担当するエージェントが、単に文書を返すのではなく、「このアラートの文脈において重要な情報はこれ」という形で要約して返すイメージです。

## 開発・インフラ関連データへのアクセス機能の提供

次に重要なのは、開発・インフラ関連のデータへのアクセス機能を提供することです。静的なドキュメントだけでなく、実際のシステムの状態を動的に取得できることが、正確な深刻度判定には不可欠です。そのためにいろいろな権限を付けたりツールを用意して、エージェントがアクセスできる状態を作ります。

- **ソースコードリポジトリへの読み取りアクセス**: アラート関連のエンドポイントやロジックの実装を直接確認できるようにします。入力検証、認証実装、使用ライブラリのバージョンなどを自動抽出する仕組みが必要です。ただし、これについては単純にアクセスできれば良いというわけではなく、コードを追跡するようなエージェントとしての振る舞いが必要です。例えば「このエンドポイントはどのように入力を検証しているか」を調べるには、ルーティング定義からハンドラを特定し、そこから呼び出されている検証関数を追跡するといった複数ステップの分析が必要になります。こうしたコード理解に特化したAIエージェント（CursorやClaude Codeなど）の方が得意な領域です。またコストも掛かるので、クリティカルそうなアラートだけに絞るといった工夫も必要になりそうです。
- **IaCおよび実際のインフラ情報の読み取り**: 権限設定、ネットワーク構成、公開範囲などをTerraformやCloudFormationといったIaC（Infrastructure as Code）から読み取ります。さらに実際のインフラにアクセスして情報を読み取る機能も必要です。例えばGoogle CloudのCloud Asset InventoryやAWSのAWS Config、Azure Resource Graphなどのサービスから現在の構成情報を取得します。BigQueryに外出しして検索するような方法もありますが、生の情報が必要になる場面も多いでしょう。
- **CI/CDパイプラインやデプロイ履歴へのアクセス**: 最近のデプロイタイミングとアラート発生時刻を突き合わせることで、デプロイ内容から新機能起因かどうかを判断できます。また、どのソースコードがどこにどういう形でデプロイされたかを追跡できることも重要です。意外とソースコードのリポジトリと実稼働プロダクトが綺麗に繋がらない場合もあります。これを人間がちまちま調べるのではなく、エージェントにやらせたいところです。

## 関係者との対話の代行

すべての情報がシステムから取得できるわけではありません。特に「このシステムの意図された挙動は何か」といった設計意図や、「この設定は一時的なものか恒久的なものか」といった運用上の判断は、担当者に聞かなければわからないこともあります。そこで、関係者に「聞く・問い合わせる」ということ自体をエージェントに代行させるアプローチも考えられます。

システムオーナーやSREへの自動問い合わせを実装します。不明な設定や意図が不明なアラートについて、チャットシステム（SlackやTeams）で質問を代行させます。そこまで高度な会話を求めなくても、「Yes」「No」で答えられるようにして、ボタンで回答させる形式で良いはずです。人間の回答を受け取った後に深刻度判定を継続します。あるいは「このアラートについて詳しい人は誰ですか」と聞いて、適切な担当者を指名してもらうといった仕組みも考えられます。

![](https://storage.googleapis.com/zenn-user-upload/265543b5fab6-20251223.png)

このアプローチの利点は、人間の知識を活用しつつ、エージェントが24時間365日稼働できることです。夜間や休日に発生したアラートでも、翌営業日に担当者が出社したタイミングで質問への回答を得て、判定を完了できます。


## マルチエージェント化

ここまでいくつか方法を挙げてきましたが、これらのアプローチは1つ1つの処理がとても複雑です。そうするとコンテキスト限界だけでなく、余計な処理によるコンテキスト汚染（不要な情報によるコンテキストの消費や、失敗情報の混入など）もかなり気にする必要がでてきます。こういった側面を考えると、やはりマルチエージェント化が必要になります。

前述の3つのアプローチ（検索性向上、データアクセス、対話代行）はそれぞれ独立した処理として実装できますが、これらを統合的に扱い、最適なタイミングで呼び出すには、マルチエージェント的なアーキテクチャが効果的です。以下では、マルチエージェント化における重要な考え方を2つ紹介します。

### タスクの専門家を作る

マルチエージェントは「セキュリティアナリスト」「インシデントレスポンス」といった専門性をエージェントごとに分離すると思われがちですが、個人的にはそれはちょっと違っていて、本質は「タスクの専門家」を作ることだと考えています。例えばここまでの例で言うと「資料検索の専門家」「ポリシー解釈の専門家」「ソースコード分析の専門家」「ログ検索の専門家」といった具合です。これは人間の単位でみる専門性とは違います。例えばAIコーディングエージェントは「ソースコードを調べたり記述する専門家」とカテゴリすることができると思います。

このような各エージェントが、それぞれに特化したツールセットを持つことでタスクを効率化できる、というのがマルチエージェントの本懐だと考えます。例えばコード分析エージェントはGitHub API、インフラエージェントはクラウドAPIといった具合です。利用できるツールが多すぎると混乱するという問題もあるので、ツールの分散はその防止策でもあります。またプロンプトなども特定の領域に絞ってチューニングすることで、よりタスクの精度を高められることが期待されます。

### エージェント間の制御

マルチエージェントについては並列性も利点として挙げられますが、これも個人的にはあまり本質ではないと考えています。直列でも正しく問題を解決できればものすごく価値があります。依存関係を事前に正確に把握することは困難であり、計画通りに並列実行しようとすると逆に複雑性が増す可能性があります。「早すぎる最適化は悪手」という格言もあります。

どちらかというとマルチエージェント全体では、複数のエージェントを「戦わせる」という制御をするのが本質かもしれません。多くの場合マルチエージェントでは、主たるエージェントがサブエージェントを使いこなすものとイメージされがちですが、並列する2つのエージェントを用意して意見を戦わせるという手法も考えられます。異なる前提や異なるモデル、プロンプトを与えることによって違う視点を持たせられます。人間の役割分担と同じく、例えばセキュリティ担当としての深刻度と事業担当者としての深刻度というのは異なってきます。そのため異なる役割を与えた時の結論は違うはずで、それを綱引きさせるというのは重要な判断においてはありえると考えています。もちろんコストや時間はかかります。

複数のエージェントでそれを判断するような仕組みが作れると、これは3つの役割から考察をして結論を導く、某スーパーコンピューターみたいになりそうです。実際に複数エージェントを戦わせる手法（ensembleやdebateなど）は研究が進められていますが、まだ実用段階ではないとのことです。逆に精度が下がる可能性もあるらしいですが、チャレンジしてみるだけの価値と夢はあるのではと考えています。

![](https://storage.googleapis.com/zenn-user-upload/ce0f7ed2a0ce-20251223.png)
_某スーパーコンピューターのストーリーは筆者がセキュリティに興味を持つきっかけでもあったので、少なからず感慨があります_

# まとめ

LLMを含む生成AIの発展は著しく、1年前の2024年12月と2025年12月ですら大きな変化がありました。未来のことを予想するのは難しいですが、引き続き生成AI関連への投資は続いていくとみられ、2026年にはまた違った景色が見えているのではないかと思います。

本書を通して何度か触れましたが、LLMをはじめとする生成AIはこれまでのソフトウェア開発のパラダイムを大きく変化させたと実感しています。これまででも機械学習などを駆使すれば実現できたこともありますが、その実現のためのハードルが大きく下がり様々なアイディアを試したり、実装できるようになりました。セキュリティの分野でも、監視に限らずまだまだ新しい活用方法や応用できることがたくさんあるのではないかと考えています。

生成AIは純粋にモデルの発展だけでなく、周辺のツールやエコシステムについても目覚ましい勢いで変化しています。実際、本書の執筆を始めた2024年10月初頭にはなかったGo向けの[Agent Development Kit](https://developers.googleblog.com/announcing-the-agent-development-kit-for-go-build-powerful-ai-agents-with-your-favorite-languages/)が11月にリリースされてちょっと焦るということもありました。実際、GoでLLMエージェントをまず試すならADKを使ったほうが確実にお手軽なのですが、仕組みの理解に役立てばという観点と、セキュリティ分析という特定のユースケースについて紹介する意義はあると考えて執筆を続けてきました。

本書で扱った内容ももしかすると来年にはもう時代遅れになっているかもしれませんが、読んでいただいた方の何かの参考になれば幸甚です。最後までお付き合いいただき、ありがとうございました。
