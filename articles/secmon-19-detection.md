---
title: "実践セキュリティ監視基盤構築(19): アラート検知の実装要点"
emoji: "🔎"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: ["security", "monitoring"]
published: false
---

この記事はアドベントカレンダー[実践セキュリティ監視基盤構築](https://adventar.org/calendars/9986)の18日目です。

今回はアラートの検知の実装について解説します。本アドベントカレンダーではBigQueryに定期的にクエリを発行してアラートを検知する、いわゆるバッチ型のアラート検知を前提としていますが、他にもストリーム型のアラート検知もあります。今回はそれぞれの実装をする場合のポイントについて解説します。

# アラート検知の処理系

アラート検知のための処理系は大きく分けて、発生したログデータを逐次的に受け付けて検知するストリーム型と、定期的にクエリを発行して検知するバッチ型があります。今回は自分で実装することを前提にしていますが、既存のSIEMなどもいずれかの方法で実装されている場合がほとんどなので。それぞれの特徴を説明します。

## ストリーム型

発生したログを1件ずつ検査し、あらかじめ定義されたルールにマッチするかどうかを判定します。ログはメッセージングサービス（例: Pub/Sub）を経由して送信されてきたり、syslog、logstash、fluentdやHTTPのAPIを経由して送信されてくるものなど様々ですが、基本的には到着したログを次々に処理していくことになります。

この実装方法の最大の利点は遅延が小さくなることです。ログが到着した段階で検知を行うため、ログの取得から検知までの遅延がほとんど発生しません。そのため、緊急度の高いアラートを検知し、即座に対応する[^respond-latency]ためには適した形であると言えます。

[^respond-latency]: ただし、アラートの対応が24/365で即座にできる体制を整えられる場合にのみ効果を発揮する点に注意してください。

一方でストリーム型の実装は複数のログに跨ったアラートを検知するのが難しい、という弱点があります。「アラート検知のためのルール設計」の節でも述べた通り、アラートの検知は1つのログだけでなく複数のログを組み合わせて検知するものも多くあります。ストリーム型の実装ではログを逐次的に処理していくため、1つのログにでてくる特徴だけでアラートを検知するのは問題ありませんが、ログ間の関係を表現しようとするならその情報を保持する必要があります。

このためのアプローチは大きく分けて以下の2つになります。

![](https://storage.googleapis.com/zenn-user-upload/76bf17bdcfbb-20241210.jpg)

### 💡 (パターン1) 短期的な記憶領域を用意し状態を保持する

定常的に稼働しているインスタンスなどであればメモリ上に、サーバレスであればCloud Firestoreなどのデータベースに状態を保持する方法です。これによってログの出現数、関連ログ観測の有無、特定のログの出現頻度などを記録し、それを元にアラートを検知します。

この方法は状態を維持・管理する実装が比較的複雑になります。例えばあるログが一定期間内に発生した件数をカウントする場合、カウントする数値をそのまま加算で保持するとします。そのあと時間が経過したら過去のログは対象期間から外れるため、その分を減算しなければなりません。

![](https://storage.googleapis.com/zenn-user-upload/6905165d12ce-20241211.jpg)

これがそれぞれ数件であればログ毎の発生時刻を全て記録しておけばいいのですが、数十万件、数百万件となると記憶領域を圧迫してしまいます。それを回避するためにはタイムスロットを設けて、そのスロット内に発生したログの数をカウントするなどの工夫が必要です。

状態遷移のルールを保つ場合はステートマシンを実装すれば良いのですが、ここで難しいのが全てのログが一律の遅延で到着するわけではない、ということです。ここまででも述べた通り、ログの提供元によって遅延はバラバラになりますし、さらに言うと同じ提供元のログでも遅延が安定しないこともあります。単純なステートマシンで状態遷移を実装すると、後から到着したログが先に到着したログよりも前の状態に必要だった、ということもあり得るため、その辺りの実装には注意が必要です。

### 💡 (パターン2) ログデータベースから都度関連するログを取得する

定常的に稼働しているインスタンスなどであればローカルディスクに、サーバレスであればデータウェアハウスにログを保存し、ルールの起点となるログを観測するたびに関連するログを取得し、その結果を元にアラートを検知します。

この方法はパターン1に比べるとシンプルに実装できます。ルールに関連したログを観測したタイミングで過去に観測されたログを全て取り出し、そのログの集合を集計、分析、検査すればよくなります。ログの遅延がバラバラだったとしても必要なログが全て揃った段階で、最も遅延を小さくして検知ができます。

一方でこの手法の問題はコストになります。検査対象とのあるログが到着するたびにデータベースにクエリをすることになるため、ルールに関連したログが多く到着するほどデータベースの負荷が高まります。あるいはBigQueryなどのサービスの場合はスキャンした容量に応じて課金が発生するため、頻繁にクエリを発行すると使用料金が大幅に上昇するおそれがあります。


### ⚠️ ストリーム型処理実装における注意点（パフォーマンス）

パターン1、2のどちらにも言えることですが、ストリーム型でアラート検知をする場合はパフォーマンスを保つことが重要です。ストリーム型は遅延を小さくすることが目的であるため、処理が遅くなると遅延が大きくなってしまい恩恵が小さくなってしまいます。

## バッチ型

- 定期的にクエリ発行する
    - 再実行がラク
    - スケジューラでCloud Runを定期実行
    - なんならCloud WorkflowでもOK
- 検知した（クエリの結果が得られた）ログをアラート処理に送る
    - 今回はPubSub
    - ただし大量に送りつけると受け側が大変なことになるのでちゃんと考える
- コストの抑制
    - 時刻パーティションの活用
        - ただしクエリする時間間隔にも影響するので注意
    - 参照フィールドを絞る
    - LIMITは効かないので注意
- 注意点
    - 検知に対して例外のルールを足していくことになる
    - ルールの見通しが悪くなって認知不可が高くなる
    - テスト可能にしておかないと徐々に破綻していく

# アラート検知実装における要点

- テスト
- 集約


# どの処理系を選ぶか


# まとめ
